{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "“2_2_ReverseAD.ipynb”的副本",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "ef88843b66adc91569384659597bfa0d",
          "grade": false,
          "grade_id": "cell-3f061ea27f528fcf",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "fiJ5uTuH8U4t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Part 3: Reverse Mode Automatic Differentiation\n",
        "\n",
        "Dynamic Reverse mode AD can be implemented by declaring a class to represent a value and the child expressions that the value depends on. We've provided the implementation that was shown in the lecture slides as a basis below, but it's missing some parts that will make it useful.\n",
        "\n",
        "__Tasks:__\n",
        "\n",
        "- Addition (`__add__`) is incomplete - can you finish it? \n",
        "- Can you also implement division (`__truediv__`), subtraction (`__sub__`) and power (`__pow__`)?"
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "2644b153f82b6e872e63cb5ead2d529f",
          "grade": false,
          "grade_id": "cell-b23d219550cd2934",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "8vmJ8R1S8U4v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "class Var:\n",
        "    def __init__(self, value):\n",
        "        self.value = value\n",
        "        self.children = []\n",
        "        self.grad_value = None\n",
        "\n",
        "    def grad(self):\n",
        "        if self.grad_value is None:\n",
        "            self.grad_value = sum(weight * var.grad()\n",
        "                                  for weight, var in self.children)\n",
        "        return self.grad_value\n",
        "    \n",
        "    def __str__(self):\n",
        "        return str(self.value)\n",
        "\n",
        "    def __mul__(self, other):\n",
        "        z = Var(self.value * other.value)\n",
        "        self.children.append((other.value, z))\n",
        "        other.children.append((self.value, z))\n",
        "        return z\n",
        "\n",
        "    def __add__(self, other):\n",
        "        #TODO: finish me\n",
        "        # YOUR CODE HERE\n",
        "        z = Var(self.value + other.value)\n",
        "        self.children.append((1, z))\n",
        "        other.children.append((1, z))\n",
        "        return z\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    # TODO: add missing methods\n",
        "    # YOUR CODE HERE\n",
        "    def __truediv__(self,other):\n",
        "        z = Var(self.value / other.value)\n",
        "        self.children.append((1 / other.value, z))\n",
        "        other.children.append((-self.value / (other.value**2), z))\n",
        "        return z   \n",
        "    \n",
        "    def __sub__(self,other):\n",
        "        z = Var(self.value - other.value)\n",
        "        self.children.append((1, z))\n",
        "        other.children.append((-1, z))\n",
        "        return z    \n",
        "    \n",
        "    def __pow__(self,other): # self**other\n",
        "        z = Var(math.pow(self.value, other.value))\n",
        "        self.children.append((other.value * (self.value ** (other.value - 1)), z))\n",
        "        other.children.append((math.pow(self.value, other.value) * math.log(self.value), z))\n",
        "        return z\n",
        "    #raise NotImplementedError()\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "afce3f80a9f8278e0ea2815a23a09c95",
          "grade": true,
          "grade_id": "cell-d2124fb6ca76110f",
          "locked": true,
          "points": 2,
          "schema_version": 1,
          "solution": false
        },
        "id": "pQbC0vuZ8U4x",
        "colab_type": "code",
        "outputId": "cab0d9df-08c2-4c33-c68d-34651a6daf18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# Tests\n",
        "\n",
        "Var(1) + Var(1) / Var(1) - Var(1)**Var(1)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.Var at 0x7fd688cb5668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "136e5e779ef4c951e75380a1554d1543",
          "grade": false,
          "grade_id": "cell-7a8d45cf51fc131f",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "5pOE3rY78U4z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Implementing math functions\n",
        "\n",
        "Just like when we were looking at Forward Mode AD, we also need to implement some core math functions. Here's the sine function for a `Var`:"
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "53148f99532fa882690bcced1654894b",
          "grade": false,
          "grade_id": "cell-1a2d833d58b9a2ec",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "I-QmDhGg8U40",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sin(x):\n",
        "    z = Var(math.sin(x.value))\n",
        "    x.children.append((math.cos(x.value), z))\n",
        "    return z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "f733095db7ef9f78d62daf4d675492d3",
          "grade": false,
          "grade_id": "cell-71185787c3ab6312",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "14Vf7jiF8U42",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__Task:__ can you implement the _cosine_ (`cos`), _tangent_ (`tan`), and _exponential_ (`exp`) functions in the code block below?"
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "6421b25426b2b125fa6de8358a1e1475",
          "grade": false,
          "grade_id": "cell-29e8985bf1eae001",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "ZOOdohMq8U43",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TODO: implement additional math functions on dual numbers\n",
        "\n",
        "def cos(x):\n",
        "    # YOUR CODE HERE\n",
        "    z = Var(math.cos(x.value))\n",
        "    x.children.append((-math.sin(x.value), z))\n",
        "    return z\n",
        "    #raise NotImplementedError()\n",
        "\n",
        "def tan(x):\n",
        "    # YOUR CODE HERE\n",
        "    z = Var(math.tan(x.value))\n",
        "    x.children.append((1 / (math.cos(x.value)**2), z))\n",
        "    return z\n",
        "    #raise NotImplementedError()\n",
        "\n",
        "def exp(x):\n",
        "    # YOUR CODE HERE\n",
        "    z = Var(math.exp(x.value))\n",
        "    x.children.append((math.exp(x.value), z))\n",
        "    return z\n",
        "    #raise NotImplementedError()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "70274a378e4b56b0b6dc2147ee44cb3d",
          "grade": true,
          "grade_id": "cell-0ed03787817557e8",
          "locked": true,
          "points": 1,
          "schema_version": 1,
          "solution": false
        },
        "id": "1gcIe0mM8U45",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Tests\n",
        "assert cos(Var(0)).value == 1\n",
        "assert tan(Var(0)).value == 0\n",
        "assert exp(Var(0)).value == 1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IqDF-rHZ8U4-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Time to try it out\n",
        "\n",
        "We're now in a position to try our implementation.\n",
        "\n",
        "__Tasks:__ \n",
        "\n",
        "- Try running the following code to compute the value of the function $z=x\\cdot y+sin(x)$ given $x=0.5$ and $y=4.2$, together with the derivative $\\partial z/\\partial x$ at that point. \n",
        "- Verify that the result is correct by hand-differentiating the function."
      ]
    },
    {
      "metadata": {
        "id": "NneWq3NO8U4_",
        "colab_type": "code",
        "outputId": "5db8f981-f923-4f6e-cfc9-35d2f242b43a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "x = Var(0.5)\n",
        "y = Var(4.2)\n",
        "z = x * y + sin(x)\n",
        "print('z:', z)\n",
        "\n",
        "z.grad_value = 1.0 #Note that we have to 'seed' the gradient of z to 1 (e.g. ∂z/∂z=1) before computing grads\n",
        "print('∂z/∂x:',x.grad())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "z: 2.579425538604203\n",
            "∂z/∂x: 5.077582561890373\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-U3uACOk8U5B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__Task:__ Now use the code block below to compute the derivative $\\partial z/\\partial y$ of the above expression (at the same point $x=0.5, y=4.2$ as above). Store the resultant gradient in the variable `dzdy`. Verify by hand that the result is correct."
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "4e1272f80f811e792100c3fd78b912f0",
          "grade": false,
          "grade_id": "cell-ab12803572df9248",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "5gHoiPXp8U5C",
        "colab_type": "code",
        "outputId": "b18546a4-f639-4e1c-c6c0-9b57bb047390",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "x = Var(0.5)\n",
        "y = Var(4.2)\n",
        "z = x * y + sin(x)\n",
        "z.grad_value = 1.0 #Note that we have to 'seed' the gradient of z to 1 (e.g. ∂z/∂z=1) before computing grads\n",
        "dzdy = y.grad()\n",
        "#raise NotImplementedError()\n",
        "\n",
        "print('∂z/∂y:', dzdy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "∂z/∂y: 0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "f9dd2f1466c7bcbd950c8a25d9af7a00",
          "grade": true,
          "grade_id": "cell-6b295b43c928fc86",
          "locked": true,
          "points": 1,
          "schema_version": 1,
          "solution": false
        },
        "id": "cmX09wSW8U5E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assert dzdy\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5lkrElLu8U5H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Differentiating Algorithms\n",
        "\n",
        "Now, let's look at doing something wacky: differentiate an algorithm. For this example, we'll use an algorithm that is in a sense static (in this particular case the upper limit of the for loop is predetermined). However, it is not difficult to see that AD is much more general, and could even be applied to stochastic algorithms (say if we replaced the upper limit of the loop below with `Math.floor(Math.random() * 10)` for example).\n",
        "\n",
        "__Task:__ Consider the following algorithm and in the box below it manually compute the value of $z$ and the gradient $\\partial z/\\partial x$ at the end of execution."
      ]
    },
    {
      "metadata": {
        "id": "6N2NEaH18U5I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = Var(0.5)\n",
        "z = Var(1)\n",
        "for i in range(0,2):\n",
        "    z = (z + Var(i)) * x * x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "a5058b059e97e150c869316d58034822",
          "grade": true,
          "grade_id": "cell-b0d4a79348257124",
          "locked": false,
          "points": 4,
          "schema_version": 1,
          "solution": true
        },
        "id": "qq7Z-K5E8U5K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "$z = (((1 + 0) * x * x) + 1) * x * x$\n",
        "\n",
        "$  = x^4 + x^2$\n",
        "\n",
        "$  = 0.3125$\n",
        " \n",
        "$∂z/∂x = 4 x^3 + 2 x = 1.5$\n"
      ]
    },
    {
      "metadata": {
        "id": "mgOKUhbq8U5L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__Task__: Now use the code block below to print out the gradient computed by our reverse AD by storing the result in a variable called `grad`. Does it match?"
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "26e9bd08a28f421e4dc79eebe8e028e8",
          "grade": false,
          "grade_id": "cell-d177505b72fe0811",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "9A5gTADt8U5M",
        "colab_type": "code",
        "outputId": "72fbd1d9-54f2-45ec-b30d-5b75678d1620",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "x = Var(0.5)\n",
        "z = Var(1)\n",
        "for i in range(0,2):\n",
        "    z = (z + Var(i)) * x * x\n",
        "z.grad_value = 1.0\n",
        "grad = x.grad()\n",
        "#raise NotImplementedError()\n",
        "\n",
        "print(grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "c6ad226117e30b08f0fdf48b929029e7",
          "grade": true,
          "grade_id": "cell-e87a4e1621ed1d18",
          "locked": true,
          "points": 2,
          "schema_version": 1,
          "solution": false
        },
        "id": "bGlwBuYN8U5O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Tests\n",
        "assert grad\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pRMHESNX8U5Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__Task:__ Finally, use the code block below to experiment and test the other math functions and methods you created."
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "59055cd24350e996850ec1b2aa532ea6",
          "grade": true,
          "grade_id": "cell-bf3e00ed03ace059",
          "locked": false,
          "points": 0,
          "schema_version": 1,
          "solution": true
        },
        "id": "AxLkYCNc8U5U",
        "colab_type": "code",
        "outputId": "211cc6d3-5282-419f-d50f-3d2be0a3ad24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "import random\n",
        "x = Var(0.5)\n",
        "z = Var(1)\n",
        "for i in range(0, random.randint(0,18)):\n",
        "    z = (z + Var(i)) * x * x\n",
        "z.grad_value = 1.0\n",
        "print(x.grad())\n",
        "#raise NotImplementedError()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "N0xN8U28iVU7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}